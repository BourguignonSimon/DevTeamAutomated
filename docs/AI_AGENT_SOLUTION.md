# AI Agent LLM Solution and Mechanism

This document explains how the Audit Flash stack integrates Large Language Models (LLMs) in a controlled, provider-agnostic way. It focuses on the gateway pattern, schema-driven outputs, and the human-in-the-loop safeguards that keep autogenerated content reliable.

## Solution Overview

- **Gateway abstraction** decouples agents from any single LLM provider. Agents call the gateway over HTTP; the gateway routes to Anthropic, OpenAI, Gemini, or a built-in fake model for tests.
- **Strict JSON schemas** are applied at the gateway to force structured outputs that match the downstream event contracts under `/schemas`.
- **Retry and provider fallback** logic lets agents request multiple providers in order of preference until one returns a schema-valid payload.
- **Human validation** is required before any autogenerated artifact is exported, preventing unchecked LLM output from reaching users.

## Components

### LLM Gateway (`services/llm_gateway`)

- **Entrypoint**: `services.llm_gateway.main:create_app` builds a FastAPI server that exposes `/v1/extract/order` and handles provider routing.
- **Provider registry**: `build_providers` wires available providers from API keys plus a `fake` provider for deterministic tests.
- **Schema enforcement**: responses are validated with the repositoryâ€™s JSON Schemas (`load_registry` + `validate_payload`), rejecting providers that fail validation.
- **Fallback loop**: each provider is tried in request-specified or default order with bounded retries per provider.
- **Observability**: warnings for unavailable providers or schema failures are aggregated into the HTTP response for traceability.

### Order Intake Agent (`services/order_intake_agent`)

- **Use case**: parsing inbox requests with attachments into structured order drafts.
- **Gateway call**: `_call_gateway` sends extracted table rows plus contextual hints (order ID, customer, delivery fields, currency) to `/v1/extract/order`.
- **Draft reconciliation**: when the gateway returns a valid draft, the agent merges missing customer/email hints, persists the draft, and emits events for downstream review.
- **Fallback behavior**: if the gateway fails or rejects providers, the agent keeps a base draft, flags the gateway as a missing field, and still requests human validation.

## End-to-End Flow

1. **Inbox event**: `ORDER.INBOX_RECEIVED` triggers parsing of attachments and initial draft creation.
2. **Gateway extraction**: the agent posts structured rows + hints to the gateway, which calls providers until a schema-valid `order_draft` is produced or all fail.
3. **Validation gating**: the agent emits `ORDER.VALIDATION_REQUIRED` and persists the draft, missing fields, and anomalies for operator review.
4. **Approval/export**: after `ORDER.VALIDATED`, the agent exports a CSV deliverable, publishes `DELIVERABLE.PUBLISHED`, and clears pending validation.

## Resilience and Safety Rails

- **Timeouts and retries**: gateway calls respect `LLM_TIMEOUT_S` and `LLM_MAX_RETRIES`, while per-provider retries inside the gateway are capped via `max_retries`.
- **Structured outputs only**: providers must return JSON conforming to `order_extraction_result.v1.schema.json`; anything else is rejected before it reaches agents.
- **DLQ-ready envelopes**: emitted events use the shared envelope helper so that standard DLQ and schema validation can catch any downstream contract issues.
- **Deterministic testing**: the `fake` provider enables local or CI runs without external LLM calls while exercising the same routing and validation paths.

## Configuration Summary

- **Gateway**: environment-driven `GatewaySettings` configure API keys, default provider order, log level, timeout, and per-provider retry budget.
- **Agents**: `OrderIntakeSettings` control the gateway URL, provider preference, HTTP timeout, and retry counts, ensuring deployments can override defaults without code changes.
- **Schemas**: the gateway and agents both load schemas from `/app/schemas`, keeping contracts centralized for validation and test fixtures.
